{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNIST.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenningBuhl/DLML/blob/master/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gv0s-9pLS7n",
        "colab_type": "text"
      },
      "source": [
        "# DLML - GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajhiU7yhlPUr",
        "colab_type": "text"
      },
      "source": [
        "Sources:\n",
        "\n",
        "1. ...\n",
        "1. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H60wQ0zWWmkM",
        "colab_type": "text"
      },
      "source": [
        "## TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3xiZI4wU9DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "- Implement GAN without Convolutions\n",
        "\n",
        "- Change single latent variable and inspect ramifications in generated image.\n",
        "- Grid of latent space and sliders to explore it\n",
        "\n",
        "- Use different data: Celeb Faces, Knitting patterns, Pokemon, Make own data, ...\n",
        "\n",
        "- t-SNE of latent space\n",
        "- 2D Manifold with classifier labels\n",
        "\n",
        "DIFFICULT! (better create new notebooks to keep code clean and retain old versions of GAN)\n",
        "- Use different loss function?\n",
        "- Use Pro GAN\n",
        "- Use VAE GAN\n",
        "- Use Style GAN\n",
        "- Use Cycle GAN\n",
        "- Use Conditional GAN\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G-0U-UzZ_OF",
        "colab_type": "text"
      },
      "source": [
        "## Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c48VbAQVXAU6",
        "colab_type": "text"
      },
      "source": [
        "- https://github.com/eriklindernoren/Keras-GAN\n",
        "- https://machinelearningmastery.com/how-to-code-generative-adversarial-network-hacks/\n",
        "- https://www.youtube.com/watch?v=dCKbRCUyop8\n",
        "- https://github.com/google/compare_gan\n",
        "- https://arxiv.org/pdf/1806.11382.pdf\n",
        "- https://arxiv.org/pdf/1812.04948.pdf\n",
        "- https://arxiv.org/pdf/1710.10196.pdf\n",
        "- https://arxiv.org/pdf/1801.04406.pdf\n",
        "- https://arxiv.org/pdf/1512.09300.pdf\n",
        "- https://medium.com/@jonathan_hui/gan-gan-series-2d279f906e7b\n",
        "- https://gist.github.com/korakot/8409b3feec20f159d8a50b0a811d3bca\n",
        "- https://www.is.mpg.de/uploads_file/attachment/attachment/426/GAN_convergence.pdf\n",
        "- https://arxiv.org/pdf/1706.04156.pdf\n",
        "- \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn9loYR0EUgQ",
        "colab_type": "text"
      },
      "source": [
        "## Random Seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qrKCK6pLN54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Numpy seed.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "# Set TensorFlow seed.\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQcuVC04Lb2K",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Wr2utpLbwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
        "from keras.layers import BatchNormalization, Dropout, ZeroPadding2D\n",
        "from keras.layers import Activation, LeakyReLU, ReLU\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.initializers import RandomNormal, glorot_normal\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist, fashion_mnist, cifar10\n",
        "\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.animation as animation\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1vvZ2GisHnP",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRvzVg9JivNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return datetime.\n",
        "def get_datetime(seconds):\n",
        "    return str(datetime.timedelta(seconds=seconds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mLd9kTksHsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return moving average of argument.\n",
        "def ema(data, window_size=100):\n",
        "    cumsum_vec = np.cumsum(np.insert(data, 0, 0)) \n",
        "    ma_vec = (cumsum_vec[window_size:] - cumsum_vec[:-window_size]) / window_size\n",
        "    return ma_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NENTT61di3wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return the norm of all gradients of trinable parameters (only works in training).\n",
        "def get_gradient_norm(model):\n",
        "    with K.name_scope('grad_norm'):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))\n",
        "    return norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPj9nMrYLbqZ",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C6p1lmCb7dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data dimensions.\n",
        "x_dim = 28\n",
        "y_dim = 28\n",
        "channels = 1\n",
        "img_shape = (x_dim, y_dim, channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_T1Z_JuMbS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "#(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0bVmWU1M1bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatonate train and test data.\n",
        "#x_train = np.concatenate((x_train, x_test))\n",
        "\n",
        "# Add channel dimension.\n",
        "x_train = x_train.reshape(-1, x_dim, y_dim, channels)\n",
        "x_test = x_test.reshape(-1, x_dim, y_dim, channels)\n",
        "\n",
        "# Normalize data to interval (-1, 1).\n",
        "x_train = x_train / 255 * 2 - 1\n",
        "x_test = x_test / 255 * 2 - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fygPY-rfOe5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print data shape.\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M6uEs_JaOYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x_train[6].reshape(x_dim, y_dim), cmap='gray_r')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdMS0cYEMbNc",
        "colab_type": "text"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng07TOXyda-W",
        "colab_type": "text"
      },
      "source": [
        "## Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqEBnPCvcU7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterations = 10000\n",
        "batch_size = 128\n",
        "latent_dim = 100\n",
        "\n",
        "init = glorot_normal() #RandomNormal(mean=0, stddev=0.02)\n",
        "optimizer = Adam(lr=0.0002, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcDV9BPMddWy",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yil1t3g3Zez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build generator model.\n",
        "z = Input(shape=(latent_dim,))\n",
        "x = Dense(128 * 7 * 7, kernel_initializer=init)(z)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Reshape((7, 7, 128))(x)\n",
        "\n",
        "x = Conv2D(128, kernel_size=3, strides=(1, 1), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "\n",
        "x = Conv2DTranspose(128, kernel_size=3, strides=(2, 2), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "\n",
        "x = Conv2D(64, kernel_size=3, strides=(1, 1), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "\n",
        "x = Conv2DTranspose(64, kernel_size=3, strides=(2, 2), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "\n",
        "x = Conv2D(channels, kernel_size=3, strides=(1, 1), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = Activation(\"tanh\")(x)\n",
        "\n",
        "generator = Model(z, x)\n",
        "generator.name = \"generator\"\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anxZx3EMHUl3",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3OWyQ1fHUhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build discriminator model.\n",
        "img_input = Input(shape=img_shape)\n",
        "x = Conv2D(32, kernel_size=3, strides=(2, 2), padding=\"same\", kernel_initializer=init)(img_input)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Conv2D(64, kernel_size=3, strides=(2, 2), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Conv2D(128, kernel_size=3, strides=(2, 2), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Conv2D(256, kernel_size=3, strides=(1, 1), padding=\"same\", kernel_initializer=init)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(1, kernel_initializer=init)(x)\n",
        "x = Activation(\"sigmoid\")(x)\n",
        "\n",
        "discriminator = Model(img_input, x)\n",
        "discriminator.name = \"discriminator\"\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "discriminator.metrics_names.append(\"grad_norm\")\n",
        "discriminator.metrics_tensors.append(get_gradient_norm(discriminator))\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQrsuOR7M7aN",
        "colab_type": "text"
      },
      "source": [
        "## Combined Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB2n_mTWM7Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the combined model we will only train the generator.\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Combined model (stacked generator and discriminator).\n",
        "combined = Model(z, discriminator(generator(z)))\n",
        "combined.name = \"combined\"\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "combined.metrics_names.append(\"grad_norm\")\n",
        "combined.metrics_tensors.append(get_gradient_norm(combined))\n",
        "\n",
        "combined.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zNvtIfKMbCs",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN8zoCKwCxes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss history.\n",
        "losses = {'d_loss' : [],\n",
        "          'd_acc' : [],\n",
        "          'g_loss' : [],\n",
        "          'd_grad_norm' : [],\n",
        "          'g_grad_norm' : []}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e-CNJtdTySj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Savely create path.\n",
        "save_path_image = \"images/\"\n",
        "if not os.path.exists(save_path_image):\n",
        "    os.mkdir(save_path_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVcYm1OxcVd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adversarial ground truths.\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "# Start time measurement.\n",
        "start = time.time()\n",
        "\n",
        "# Save interval settings.\n",
        "save_interval = 50\n",
        "use_static_noise = True\n",
        "r, c = 5, 5\n",
        "static_noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "save_paths = []\n",
        "\n",
        "for iteration in range(iterations):\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Discriminator\n",
        "    # ---------------------\n",
        "\n",
        "    # Select a random half of images.\n",
        "    idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "    imgs = x_train[idx]\n",
        "\n",
        "    # Sample noise and generate a batch of new images.\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Train the discriminator (real classified as ones and generated as zeros).\n",
        "    d_loss_real, d_acc_real, d_grad_norm_real = discriminator.train_on_batch(imgs, valid)\n",
        "    d_loss_fake, d_acc_fake, d_grad_norm_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "    # Calculate discriminator metrics (average of real and fake batches) to record.\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    d_acc = 0.5 * np.add(d_acc_real, d_acc_fake)\n",
        "    d_grad_norm = 0.5 * np.add(d_grad_norm_real, d_grad_norm_fake)\n",
        "\n",
        "    # Log discriminator metrics.\n",
        "    losses['d_loss'].append(d_loss.tolist())\n",
        "    losses['d_acc'].append(d_acc.tolist())\n",
        "    losses['d_grad_norm'].append(d_grad_norm.tolist())\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Generator\n",
        "    # ---------------------\n",
        "\n",
        "    # Sample novel noise.\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "    # Train the generator (wants discriminator to mistake images as real).\n",
        "    g_loss, g_grad_norm = combined.train_on_batch(noise, valid)\n",
        "    \n",
        "    # Log generator metrics.\n",
        "    losses['g_loss'].append(g_loss)\n",
        "    losses['g_grad_norm'].append(g_grad_norm)\n",
        "\n",
        "    # Print progress.\n",
        "    print(\"Iteration: {:5d} [D loss: {:1.5f}, acc.: {:5.2f}%, grad norm: {:5.2f}] [G loss: {:1.5f}, grad norm: {:5.2f}]\".format(\n",
        "        iteration + 1, d_loss, 100 * d_acc, d_grad_norm, g_loss, g_grad_norm))\n",
        "\n",
        "    # Save generated image samples.\n",
        "    if (iteration + 1) % save_interval == 0 or (iteration + 1) == 1:\n",
        "        if use_static_noise:\n",
        "            noise = static_noise # Use static noise.\n",
        "        else:\n",
        "            noise = np.random.normal(0, 1, (r * c, latent_dim)) # Use new radom noise every save iteration.\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray_r')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.suptitle(\"Iteration: {:d}\".format(iteration + 1))\n",
        "        iter_save_path = \"{:s}iteration_{:d}.png\".format(save_path_image, iteration + 1)\n",
        "        save_paths.append(iter_save_path)\n",
        "        fig.savefig(iter_save_path)\n",
        "        plt.show()\n",
        "\n",
        "    # Finish time measurement.\n",
        "    if (iteration + 1) == iterations:\n",
        "        end = time.time()\n",
        "        training_time = end - start\n",
        "        print('Finished training in {:s}'.format(get_datetime(training_time)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36nnR7xADdhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Savely create path.\n",
        "save_path_training = \"training/\"\n",
        "if not os.path.exists(save_path_training):\n",
        "    os.mkdir(save_path_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypyiG1uX0Y_X",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Create animation of generated images during trainig.\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for save_path in save_paths:\n",
        "    im = plt.imshow(mpimg.imread(save_path) , cmap='gray_r', animated=True)\n",
        "    plt.axis('off')\n",
        "    ims.append([im])\n",
        "plt.close()\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
        "ani.save('{:s}training.mp4'.format(save_path_training))\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0EuYspXMa-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot generator and discriminator loss.\n",
        "d_loss = np.array(losses['d_loss'])\n",
        "g_loss = np.array(losses['g_loss'])\n",
        "\n",
        "plt.plot(d_loss, label=\"D loss\")\n",
        "plt.plot(g_loss, label=\"G loss\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.savefig(\"{:s}D and G loss\".format(save_path_training))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-Gz9hFvGXx8",
        "colab": {}
      },
      "source": [
        "# Plot discriminator accuracy.\n",
        "d_acc = np.array(losses['d_acc'])\n",
        "\n",
        "d_acc_ema = ema(d_acc, window_size=100)\n",
        "\n",
        "plt.plot(d_acc, label=\"D acc\")\n",
        "plt.plot(d_acc_ema, label=\"D acc (ema)\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.savefig(\"{:s}D acc\".format(save_path_training))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOY0Tt3aZTwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot generator and discriminator gradient norm.\n",
        "d_grad_norm = np.array(losses['d_grad_norm'])\n",
        "g_grad_norm = np.array(losses['g_grad_norm'])\n",
        "\n",
        "plt.plot(d_grad_norm, label=\"D grad norm\")\n",
        "plt.plot(g_grad_norm, label=\"G grad norm\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.savefig(\"{:s}D and G grad norm\".format(save_path_training))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsf3ToHdTLkY",
        "colab_type": "text"
      },
      "source": [
        "## Save and Load GAN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x92vB1Noidq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Savely create path.\n",
        "model_path = \"models/\"\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "\n",
        "discriminator_path = model_path + \"discriminator.h5\"\n",
        "generator_path = model_path + \"generator.h5\"\n",
        "combined_path = model_path + \"combined.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKwaPyFOHCbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save models.\n",
        "discriminator.save(discriminator_path)\n",
        "generator.save(generator_path)\n",
        "combined.save(combined_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfWxoOW2HCYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load models.\n",
        "generator = load_model(generator_path)\n",
        "discriminator = load_model(discriminator_path)\n",
        "combined = load_model(combined_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2EfOGR2EhLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYLaMP4oEjYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSjC8fCjEjV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csyq-t0wTNvg",
        "colab_type": "text"
      },
      "source": [
        "## Generate from Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3TolMAFCcCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Savely create path.\n",
        "save_path_gen_image = \"gen_images/\"\n",
        "if not os.path.exists(save_path_gen_image):\n",
        "    os.mkdir(save_path_gen_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhmQAHteTTG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate images from random noise z.\n",
        "r, c = 5, 5\n",
        "noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "gen_imgs = generator.predict(noise)\n",
        "\n",
        "fig, axs = plt.subplots(r, c)\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray_r')\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "\n",
        "fig.suptitle(\"Generated Images\")\n",
        "fig.savefig(\"{:s}gen_image.png\".format(save_path_gen_image))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t__KpbhFNNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize latent space travel from point A to point B.\n",
        "intermediate_steps = 100\n",
        "\n",
        "# Points in z.\n",
        "point_a = np.random.normal(0, 1, (1, latent_dim))\n",
        "point_b = np.random.normal(0, 1, (1, latent_dim))\n",
        "#point_a = np.full((1, latent_dim), -1)\n",
        "#point_b = np.full((1, latent_dim), 1)\n",
        "\n",
        "points_travel = np.array(\n",
        "    [point_a + (point_b - point_a) * x / intermediate_steps for x in range(0, 1 + intermediate_steps)]).reshape(-1, latent_dim)\n",
        "\n",
        "# Images generated from z.\n",
        "image_a = generator.predict(point_a)\n",
        "image_b = generator.predict(point_b)\n",
        "images_travel = generator.predict(points_travel)\n",
        "\n",
        "# Show origin and destination image.\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].imshow(image_a.reshape(x_dim, y_dim), cmap='gray_r')\n",
        "axs[0].axis('off')\n",
        "axs[0].title.set_text(\"Origin image\")\n",
        "axs[1].imshow(image_b.reshape(x_dim, y_dim), cmap='gray_r')\n",
        "axs[1].axis('off')\n",
        "axs[1].title.set_text(\"Destination image\")\n",
        "plt.show()\n",
        "\n",
        "# Create animation.\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for image_travel in images_travel:\n",
        "    im = plt.imshow(image_travel.reshape(x_dim, y_dim), cmap='gray_r', animated=True)\n",
        "    plt.axis('off')\n",
        "    ims.append([im])\n",
        "plt.close()\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
        "ani.save('latent_travel.mp4')\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM5yMulWJB7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Travel freely through latent space.\n",
        "n_travel = 1000\n",
        "points = []\n",
        "images = []\n",
        "\n",
        "# Initial points.\n",
        "#point_prev = np.full((1, latent_dim), 0)\n",
        "point_prev = np.random.normal(0, 1, (1, latent_dim))\n",
        "point_curr = point_prev + 0.1 * np.random.uniform(-0.1, 0.1, (1, latent_dim))\n",
        "\n",
        "# Travel.\n",
        "print(\"Calculating travel points...\")\n",
        "for i in range(n_travel):\n",
        "    direction = (point_prev - point_curr) + 0.25 * np.random.uniform(-0.1, 0.1, (1, latent_dim))\n",
        "    point = point_prev + direction\n",
        "    point = point.clip(min=-3, max=3)\n",
        "    points.append(point)\n",
        "    point_curr = point_prev\n",
        "    point_prev = point\n",
        "\n",
        "points = np.array(points).reshape(-1, latent_dim)\n",
        "images = generator.predict(points)\n",
        "\n",
        "# Create animation.\n",
        "print(\"Creating animation...\")\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for image in images:\n",
        "    im = plt.imshow(image.reshape(x_dim, y_dim), cmap='gray_r', animated=True)\n",
        "    plt.axis('off')\n",
        "    ims.append([im])\n",
        "plt.close()\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
        "ani.save('latent_travel_n.mp4')\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xudQHiw7fTwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grid with sliders...\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqZKcVvZTS1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2D Manifold,\n",
        "if latent_dim == 2:\n",
        "    m = 1\n",
        "    n = 30\n",
        "\n",
        "    figure = np.zeros((x_dim * n, y_dim * n))\n",
        "    #figure = plt.figure(figsize=(12,8))\n",
        "\n",
        "    # Sample n points within std_devs.\n",
        "    grid_x = np.linspace(-m, m, n)\n",
        "    grid_y = np.linspace(-m, m, n)\n",
        "\n",
        "    # Draw n by n grid.\n",
        "    for i, yi in enumerate(grid_x):\n",
        "        for j, xi in enumerate(grid_y):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = generator.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(x_dim, y_dim)\n",
        "            figure[i * x_dim: (i + 1) * x_dim,\n",
        "                  j * y_dim: (j + 1) * y_dim] = digit\n",
        "\n",
        "    plt.figure(figsize=(24, 12))\n",
        "    plt.imshow(figure)\n",
        "    plt.savefig(\"2d_manifest_grid.png\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuB2jW3LG_xI",
        "colab_type": "text"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCBjFdHRHEpZ",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M66EBYB4HEkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create classifier model.\n",
        "classifier = Sequential()\n",
        "classifier.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=img_shape))\n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(128, activation='relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(10, activation='softmax'))\n",
        "\n",
        "classifier.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRIjIZKQG_nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train classifier.\n",
        "classifier_history = classifier.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTRXuPxuZqCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training and validation loss.\n",
        "plt.plot(classifier_history.history['loss'], label=\"loss\")\n",
        "plt.plot(classifier_history.history['val_loss'], label=\"val loss\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxlqW1BaYxkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training and validation accuracy.\n",
        "plt.plot(classifier_history.history['acc'], label=\"accuracy\")\n",
        "plt.plot(classifier_history.history['val_acc'], label=\"val accuracy\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLxVW12GGkCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print testing loss and accuracy.\n",
        "test_eval = classifier.evaluate(x_test, y_test)\n",
        "print(\"Testing Loss:    {:1.7f}\".format(test_eval[0]))\n",
        "print(\"Testing Accracy: {:5.2f}%\".format(test_eval[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwhpe02Yb-kf",
        "colab_type": "text"
      },
      "source": [
        "## Save and Load Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4TKT2H8olvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Savely create path.\n",
        "model_path = \"models/\"\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "\n",
        "classifier_path = model_path + \"classifier.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZvCDPIOpcEKA",
        "colab": {}
      },
      "source": [
        "# Save models.\n",
        "classifier.save(classifier_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DZZhjfuBcEKG",
        "colab": {}
      },
      "source": [
        "# Load models.\n",
        "classifier = load_model(classifier_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHg5mChglxPZ",
        "colab_type": "text"
      },
      "source": [
        "## Classifying Generated Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eImJj-3tHZNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Savely create path.\n",
        "save_path_gen_classify = \"gen_classify/\"\n",
        "if not os.path.exists(save_path_gen_classify):\n",
        "    os.mkdir(save_path_gen_classify)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VLEaR_mlxLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot generated images with classifier labels.\n",
        "r, c = 5, 5\n",
        "noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "gen_imgs = generator.predict(noise)\n",
        "preds = classifier.predict(gen_imgs)\n",
        "\n",
        "fig, axs = plt.subplots(r, c)\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray_r')\n",
        "        axs[i,j].axis('off')\n",
        "        axs[i,j].title.set_text(\"Pred:{:d}\".format(np.argmax(preds[cnt])))\n",
        "        cnt += 1\n",
        "fig.suptitle(\"Generated Images Classified\")\n",
        "fig.savefig(\"{:s}gen_classify.png\".format(save_path_gen_classify))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imbKXElrlkCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create 2D Manifold with classifier labels.\n",
        "if latent_dim == 2:\n",
        "    pass\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_fs3SJQALhQ",
        "colab_type": "text"
      },
      "source": [
        "## Classifying Hand-Drawn Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnEWFt4yALUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<canvas width=%d height=%d style=\"border:1px solid #000000;\"></canvas>\n",
        "<button>Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(filename='drawing.png', w=200, h=200, line_width=1):\n",
        "    display(HTML(canvas_html % (w, h, line_width)))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return len(binary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoDyniXCALRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let user draw.\n",
        "side_length = 300\n",
        "draw(w=side_length, h=side_length, line_width=side_length // 15)\n",
        "\n",
        "# Pre-process image.\n",
        "drawing = Image.open('drawing.png')\n",
        "drawing = np.array(drawing)\n",
        "drawing = drawing[:, :, 3]\n",
        "drawing = cv2.resize(drawing, dsize=(x_dim, y_dim), interpolation=cv2.INTER_AREA)\n",
        "drawing = drawing / 255 * 2 - 1\n",
        "\n",
        "# Make prediction.\n",
        "pred = classifier.predict(drawing.reshape(1, x_dim, y_dim, channels))\n",
        "\n",
        "# Show result.\n",
        "plt.imshow(drawing, cmap='gray_r')\n",
        "plt.title(\"Pred: {:d}\".format(np.argmax(pred[0])))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVaSm7aQb381",
        "colab_type": "text"
      },
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KJouN0_lKqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKJOHqezlKnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mNo-D_7xcgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM6PN0rEHv_L",
        "colab_type": "text"
      },
      "source": [
        "# Novel Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHWcozg5lR5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DERma1PlR2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi4utG4klR0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4j27rxhebmu",
        "colab_type": "text"
      },
      "source": [
        "# Deprecated Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MNl6Lc6eZ-r",
        "colab": {}
      },
      "source": [
        "# Travel through latent space (uneven path).\n",
        "r, c = 5, 5\n",
        "init_noise = np.random.normal(0, 1, (latent_dim,))\n",
        "noise_center = np.tile(init_noise, (r * c, 1))\n",
        "noise = noise_center + np.random.normal(0, 0.2, (r * c, latent_dim))\n",
        "gen_imgs = generator.predict(noise)\n",
        "\n",
        "fig, axs = plt.subplots(r, c)\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray_r')\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "fig.suptitle(\"Generated Images\")\n",
        "fig.savefig(\"{:s}gen_image_{:d}.png\".format(save_path_gen_image, gen_count))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "gen_count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsTzoH3a90Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate from constant value.\n",
        "r, c = 5, 5\n",
        "noise = np.full((1, latent_dim), -0.5)\n",
        "gen_imgs = generator.predict(noise)\n",
        "\n",
        "plt.imshow(gen_imgs[0, :, :, 0], cmap='gray_r')\n",
        "plt.title(\"Generated Image\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU8523tzebeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explore latent space by taking random mini steps.\n",
        "intermediate_steps = 1\n",
        "n_travel = 50\n",
        "images_travel = []\n",
        "images = []\n",
        "\n",
        "# Points in z.\n",
        "#point_init = np.random.normal(0, 1, (1, latent_dim))\n",
        "point_init = np.full((1, latent_dim), -5)\n",
        "point_b = point_init\n",
        "images.append(generator.predict(point_b))\n",
        "\n",
        "for i in range(n_travel):\n",
        "    point_a = point_b\n",
        "\n",
        "    point_b = point_a + np.random.uniform(low=-0.1, high=0.5)\n",
        "    \n",
        "    points_travel = np.array(\n",
        "        [point_a + (point_b - point_a) * x / intermediate_steps for x in range(0, 1 + intermediate_steps)]).reshape(-1, latent_dim)\n",
        "\n",
        "    # Images generated from z.\n",
        "    image_a = generator.predict(point_a)\n",
        "    image_b = generator.predict(point_b)\n",
        "    images.append(image_b)\n",
        "    images_travel.append(points_travel)\n",
        "images_travel = np.array(images_travel).reshape(-1, latent_dim)\n",
        "images_travel = generator.predict(images_travel)\n",
        "\n",
        "# Create animation.\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for image_travel in images_travel:\n",
        "    im = plt.imshow(image_travel.reshape(x_dim, y_dim), cmap='gray_r', animated=True)\n",
        "    plt.axis('off')\n",
        "    ims.append([im])\n",
        "plt.close()\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
        "ani.save('latent_travel_steps.mp4')\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNEn-rnN-jcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize latent space travel through multiple points.\n",
        "intermediate_steps = 25\n",
        "n_travel = 50\n",
        "images_travel = []\n",
        "images = []\n",
        "\n",
        "# Points in z.\n",
        "point_init = np.random.normal(0, 1, (1, latent_dim))\n",
        "point_b = point_init\n",
        "images.append(generator.predict(point_b))\n",
        "\n",
        "for i in range(n_travel):\n",
        "    point_a = point_b\n",
        "\n",
        "    if i == n_travel - 1:\n",
        "        point_b = point_init\n",
        "    else:\n",
        "        point_b = np.random.normal(0, 1, (1, latent_dim))\n",
        "    \n",
        "    points_travel = np.array(\n",
        "        [point_a + (point_b - point_a) * x / intermediate_steps for x in range(0, 1 + intermediate_steps)]).reshape(-1, latent_dim)\n",
        "\n",
        "    # Images generated from z.\n",
        "    image_a = generator.predict(point_a)\n",
        "    image_b = generator.predict(point_b)\n",
        "    images.append(image_b)\n",
        "    images_travel.append(points_travel)\n",
        "images_travel = np.array(images_travel).reshape(-1, latent_dim)\n",
        "images_travel = generator.predict(images_travel)\n",
        "\n",
        "# Show all traversed images.\n",
        "fig, axs = plt.subplots(1, n_travel)\n",
        "for (image, ax) in zip(images, axs):\n",
        "    #plt.figure(figsize=(2,2))\n",
        "    ax.imshow(image.reshape(x_dim, y_dim), cmap='gray_r')\n",
        "    ax.axis('off')\n",
        "    #plt.title()\n",
        "plt.show()\n",
        "\n",
        "# Create animation.\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for image_travel in images_travel:\n",
        "    im = plt.imshow(image_travel.reshape(x_dim, y_dim), cmap='gray_r', animated=True)\n",
        "    plt.axis('off')\n",
        "    ims.append([im])\n",
        "plt.close()\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
        "ani.save('latent_travel_n.mp4')\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYl-iwt6ebbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform arithmetics on latent vectors.\n",
        "\n",
        "# Points in z.\n",
        "point_a = np.random.normal(0, 1, (1, latent_dim))\n",
        "point_b = np.random.normal(0, 1, (1, latent_dim))\n",
        "#point_a = np.full((1, latent_dim), -1)\n",
        "#point_b = np.full((1, latent_dim), 1)\n",
        "\n",
        "# Images generated from z.\n",
        "image_a = generator.predict(point_a)\n",
        "image_b = generator.predict(point_b)\n",
        "\n",
        "# Generate images after arithmetics operations\n",
        "point_a_minus_b = point_a - point_b\n",
        "point_a_plus_b = point_a + point_b\n",
        "image_a_minus_b = generator.predict(point_a_minus_b)\n",
        "image_a_plus_b = generator.predict(point_a_plus_b)\n",
        "\n",
        "# Show image a and iamge b image.\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].imshow(image_a.reshape(x_dim, y_dim), cmap='gray_r')\n",
        "axs[0].axis('off')\n",
        "axs[0].title.set_text(\"Image A\")\n",
        "axs[1].imshow(image_b.reshape(x_dim, y_dim), cmap='gray_r')\n",
        "axs[1].axis('off')\n",
        "axs[1].title.set_text(\"Image B\")\n",
        "plt.show()\n",
        "\n",
        "# Show newly calculated images.\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].imshow(image_a_minus_b.reshape(x_dim, y_dim), cmap='gray_r')\n",
        "axs[0].axis('off')\n",
        "axs[0].title.set_text(\"A - B\")\n",
        "axs[1].imshow(image_a_plus_b.reshape(x_dim, y_dim), cmap='gray_r')\n",
        "axs[1].axis('off')\n",
        "axs[1].title.set_text(\"A + B\")\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "points_travel = np.array(\n",
        "    [point_a + (point_b - point_a) * x / intermediate_steps for x in range(0, 1 + intermediate_steps)]).reshape(-1, latent_dim)\n",
        "\n",
        "images_travel = generator.predict(points_travel)\n",
        "\n",
        "# Create animation.\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for image_travel in images_travel:\n",
        "    im = plt.imshow(image_travel.reshape(x_dim, y_dim), cmap='gray_r', animated=True)\n",
        "    plt.axis('off')\n",
        "    ims.append([im])\n",
        "plt.close()\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
        "ani.save('latent_travel.mp4')\n",
        "HTML(ani.to_html5_video())\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "872Wz_GIlb3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWsKz3NXlb1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-a3VoFalbyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}